---
title: 'Instructions: Homework #11'
author: "Data Science for Biologists, Fall 2021"
date: "Complete the template Rmd and submit to Canvas on Wednesday 11/24/21 by 2 PM"
output: 
  html_document:
    theme: lumen
    highlight: tango
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, include=F, fig.width = 6, fig.height = 4, message = F, warning = F)

library(tidyverse)
library(ds4b.materials)
```


```{css, echo=F}
ul :last-child, ol :last-child,ul :first-child, ol :first-child {
    margin-bottom: 0;
    padding-bottom:0;
}

blockquote {
  margin-left: 50px;
  border-left: 5px solid #DF4469;
  font-size:1em;
}
```


### Obtaining and setting up the homework

+ Obtain the homework template from your RStudio Cloud class project by running the following code in the R Console:

  ```{r, eval=FALSE, echo=T, include=T}
  library(ds4b.materials) # Load the class library
  launch_homework(11)      # Launch Homework 11
  ```

+ You must set an _RMarkdown theme and code syntax highlighting scheme_ of your choosing in the YAML front matter. These links will help you:
  + Choose your favorite _theme_ among the **pre-packaged themes** (ignore everything below "Even More Themes") shown at [this link](https://www.datadreaming.org/post/r-markdown-theme-gallery/)
  + Choose your favorite _syntax highlighting_ among these options at [this link](https://www.garrickadenbuie.com/blog/pandoc-syntax-highlighting-examples/)
+ **Make sure your Rmd knits without errors before submitting.** If it does not produce an HTML output, this means it does not knit. _DO NOT SKIP THIS STEP!_ Ensuring code runs without errors is MORE IMPORTANT than writing code in the first place.
  + If there are errors in your code, you should *comment out* the code so that it does not actually run. This is **BETTER** than keeping the buggy code in there without commenting out - _it shows me you attempted the code, but understood that it didn't work properly._ Partial credit will come to you! But, if you leave buggy code in, then the Rmd will not knit and there will be deductions.
+ As always, you are encouraged to work together and use the class Slack to help each other out, but you must submit YOUR OWN CODE.
<br><br>


## Questions

> Caution: This homework is VERY short, which means each question is worth a lot of points. This is both a blessing and a curse. Plan accordingly. 

For your assignment, you will be building and evaluating a logistic regression from a dataset of various physical measurements from 752 adult [Pima Native American women](https://en.wikipedia.org/wiki/Pima_people), some of whom are Type II Diabetic and some are not. Your goal for this assignment is to build and evaluate a model from this data to **predict whether an individual has Type II Diabetes** (column `diabetic`). Other columns in this dataset include:

+ `npreg`: number of times pregnant
+ `glucose`: plasma glucose concentration at 2 hours in an oral glucose tolerance test (units: mg/dL)
+ `dbp`: diastolic blood pressure (units: mm Hg)
+ `skin`: triceps skin-fold thickness (units: mm)
+ `insulin`: 2-hour serum insulin level (units: Î¼U/mL)
+ `bmi`: Body Mass Index
+ `age`: age in years
+ `diabetic`: whether or not the individual has diabetes ("Yes" or "No"). (This is your "outcome" column!)

<br><br>

1. **Prepare the data for modeling:** The `glm()` function that we use to perform a logistic regression in R really really wants the response variable to contain values 0 and 1, where 0 corresponds to so-called "failure" and 1 corresponds to so-called "success." In addition, `glm()` gets very upset when there are `NA`s anywhere in the data. Therefore, for this question, create a new version of the `pima` that contains no `NA`s, and the column `diabetic` contains *0 instead of "No" and 1 instead of "Yes"* (we consider not diabetic as "failure" and diabetic as "success"). **Save the tibble as `pima_01`, and then print it out. _This is the tibble you will use for the rest of the homework!_**


<br> 


2. **Build two candidate models:** Rather than using model selection for this homework, you will practice logistic regression by comparing two potential candidate models. (There will not be any training/testing on this HW, but please remember that in the "real world" one should always perform build a model with a validation procedure!) For this question, build these two models and calculate their AUCs. **In one _markdown_ sentence, explain which model is preferred and why.**

    + Candidate model 1 should have the following predictors:
      + `glucose`
      + `dbp`
      + `skin`
    + Candidate model 2 should have the following predictors:
      + `insulin`
      + `skin`  
      + `age`

<br>

3. **Plot the ROC curves for both candidate models.** Create a tibble of the data needed to plot both ROC curves (one for each candidate model), and then use that data to make a figure with two ROC curves. Curves should be colored by candidate model with a non-default palette, and the plot should include a guiding line representing "random chance." Do not facet - curves should be in a single panel, distinguished only by color, as was shown in class.

<br><br>

4. **Plot the logistic curve for the preferred model.** Now that you know which model is preferred (either Candidate 1 or Candidate 2!), visualize that model's logistic curve. Create a tibble of the data needed to plot the logistic curve (as done in class!), and then create your plot which should have....
    + A **black** logistic curve.
    + Indications of the true diabetic status, EITHER as...
      + Transparent colored points based on diabetic status along the curve. Must be transparent enough to see the curve!
      + A colored point rug. 
      + Either way, use non-default colors. 
    + Ensure that your legend says "Diabetic"/"Not diabetic" instead of "1" and "0". *This will be part of your initial tibble creation with a little wrangling.*
    

<br><br>

5. **Model metrics**: Again considering only the preferred candidate model, determine the following give performance measures for this model using a success threshold of *>=0.90*. Specifically...
    + First, you will need to create the tibble that contains counts for TP, FP, TN, and FN at the 90% threshold. Save this tibble to `pima_confusion` and print it out.
    + Then, use the values in the tibble to calculate and print the five measures below. For some bonus points, incorporate a `tidyr` pivot function into your code and perform all calculations using `dplyr` strategies. For regular full-credit without bonus, you are welcome to "use R as a calculator" using values seen in `pima_confusion`. *But remember: No code, no credit. No arithmetic in your head.* 
    + *You don't have to write anything else in markdown, but ensure these calculated values are printed out, and __your code is commented to clearly state which calculation is which__*.
      + Accuracy
      + False discovery rate
      + True positive rate (aka sensitivity aka recall)
      + False positive rate
      + Positive predictive value (aka precision)


<br><br>


6. **Prediction**: A new Pima woman has arrived! Use the preferred model to predict whether she is diabetic. Write code and then **answer in a brief markdown sentence**: What is the probability according to our model that she has diabetes, and at a 90% success threshold, would this model classify her as Diabetic or Not Diabetic?

    *Hint: Do you need all this information? In fact you do not!* For full credit, make sure your code is only considering predictors that are relevant for answering the question. In other words, your code should not use any data the model doesn't need.
    + `npreg`: 4
    + `glucose`: 127
    + `dbp`: 92
    + `skin`: 28
    + `insulin`: 160
    + `bmi`: 31
    + `age`: 44
