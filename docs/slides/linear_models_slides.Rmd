---
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [default, my_chocolate.css, chocolate-fonts]
    nature:
      highlightStyle:  github
      highlightLines: true
      countIncrementalSlides: false
    seal: false
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(message=F, warning=F,fig.width=8, fig.height=6)
library(xaringan)
library(tidyverse)
library(cowplot)
library(patchwork)
library(colorblindr)
img_path <- "img/lm/"

theme_set(theme_classic() + theme(axis.text = element_text(size = rel(1.75)),
                               axis.title = element_text(size = rel(1.75)),
                               legend.title = element_text(size = rel(1.75)),
                               legend.text = element_text(size = rel(1.75))
                               ))
```


class: title-slide
background-image: url(slide_background_images/hawaii.jpg) 
background-size: contain

# Stesh went to Hawaii!
<br><br><br><br><br><br><br><br><br><br><br><br><br><br>
**This is a picture taken on my vacation in 2017 to Hawaii. This picture was taken on the main island of Oahu at Kualoa Ranch. This valley has been filmed in many movies including Jurassic Park, Jurassic World, Jumanji, King Kong, and Godzilla to name a few.**


---

.bg-text[
# Introduction to linear models
## Data Science for Biologists

<hr />
**Dr. Spielman**
]

---

# CAVEAT: This is not a statistics class

### We will learn _to perform analyses and interpret results_  using a few common modeling approaches used in data science industry

### We will NOT be diving into the technical derivations or gnarly innards of the statistics of these models

### If you want to pursue data science down the line, _you will eventually need to know the technical aspects too._

---

# Machine Learning and AI



```{r out.width = '500px', echo=F}
knitr::include_graphics(file.path(img_path, "ml_ai_dl.png"))
```

---

```{r out.width = '600px', echo=F}
knitr::include_graphics(file.path(img_path,"ML_super_unsuper.png")) 
```



```{r out.width = '700px', echo=F}
knitr::include_graphics(file.path(img_path,"classif_regre.png"))
```




---

# Linear regression and linear models


---

# Everything you've learned is a ~~drum~~ ~~path~~ linear model!


+ Correlation
  + Pearson's correlation is what you know: $-1 < r < 1$
+ Regression
+ ANOVA, ANCOVA, MANOVA, etc.
+ *t*-tests and $X^2$-tests
+ Wilcoxon/Mann-Whitney U tests, sign tests


**Want to prove this to yourself? (advanced):** [https://lindeloev.github.io/tests-as-linear/](https://lindeloev.github.io/tests-as-linear/)

--

### The goal of linear modeling is to _explain variation in a variable of interest_ 

In the applied "machine learning" world, we also use models to _predict future outcomes for that variable of interest_
---

# What does "explain variation" mean?

```{r, echo=F, fig.height = 4, fig.width = 12}
tibble(x = 1:20/10, y = 4) %>%
  ggplot(aes(x=x,y=y)) + geom_point() +
  labs(x = "Predictor", y = "Response") + ylim(2,6)-> a

set.seed(33)
iris %>%
  sample_n(20) -> subiris

subiris %>%
  ggplot(aes(x=Sepal.Length,y=Sepal.Width)) + geom_point() + 
  labs(x = "Predictor", y = "Response") -> b

tibble(x = 1:20/10, y = 1:20/10) %>%
  ggplot(aes(x=x,y=y)) + geom_point() +
  labs(x = "Predictor", y = "Response") + ylim(0,2) + xlim(0,2)-> d

a + b + d

```

---
# Simple linear regression:


.large[
\begin{equation} 
  Y = \beta_1X_1 + \beta_0 + \epsilon
\end{equation} 
]

```{r, fig.width = 7, fig.height = 4}
ggplot(iris, aes(x = Sepal.Length,
                 y = Sepal.Width)) + 
  geom_point() +
  geom_smooth(method = "lm") + 
  labs(x = "Sepal Length", y = "Sepal Width")
```

---
# But don't forget species:


```{r, fig.width = 6, fig.height = 3.75}
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width,
                 color = Species)) + #<< 
  geom_point() + geom_smooth(method = "lm") + 
  labs(x = "Sepal Length", y = "Sepal Width")
```

**In this example, if we "ignore" species, we are missing the true _positive relationship_ between sepal width and length. This is called _controlling for species._**

---



# We will learn two types of _generalized linear models_ 

**Linear regression/model**: Use this method when the response is a **numeric variable**
+ Key assumptions:
  + Any numeric predictors are linearly related to the response
  + The values of the response variable have equal variance across categories of any categorical predictor
  + The *residuals* of the model are normally distributed. There is NO REQUIREMENT for the data itself to follow a normal distribution
  + Predictors should be independent of one another
  
**Logistic regression/model**: Use this method when the response is a **binary variable** 
+ We'll learn this next!

---


# What is the goal of GLMs?

+ We want to explain variation in a _response variable_ using all suitable predictors
  + How does one determine "suitable predictors"?

--

.pull-left[
### Hypothesis-testing ("science")
.small[
+ Predictors are based on experimental setup
+ *Specific* goal of knowing how those *specific* predictors affect response
]]

.pull-right[
### Exploratory ("industry"/"big-data")
.small[
+ You have _a bunch_ of data and need to figure out, which predictors should I use in my model to best explain the response?
+ Less likely you care about specific effects of individual predictors
+ *In _this class_, we are going to learn GLMs from this _perspective._*
]]


---

# Linear models

.left-column[
.large[
\begin{equation} 
  Y = \beta_1X_1 + \beta_0 + \epsilon
\end{equation} 

<br><br><br>

\begin{equation} \label{eq:full}
  Y =  \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3X_3 ... + \beta_NX_N + \epsilon
\end{equation} 
]]

---

The relationship between the age of a given lion the the proportion of its nose that is black (nose color changes over time!). [Source](https://www.amazon.com/Analysis-Biological-Data-Michael-Whitlock/dp/1936221489)


```{r out.width = '450px', echo=F}
knitr::include_graphics(file.path(img_path, "whitlock_17.1-1.png"))
```

**Fitting a model** in this case means determining the line-of-best-fit, aka determining the _optimal values_ for slope and intercept (*model parameters*)

---

# Residuals: Distance from each point to line-of-best-fit

+ Residuals are *errors* - how much does each point deviate (literally, distance) from the *average relationship*? Every point has a residual value.

+ Best-fitting line is the line with the *smallest possible* **R**esidual **S**um of **S**quares (RSS)
  + Literally the sum of the squared lengths of each residual line

```{r out.width = '950px', echo=F}
knitr::include_graphics(file.path(img_path, "whitlock_17.1-2.png"))
```

---

# Focus on the "smallest deviations" panel 

```{r out.width = '800px', echo=F}
knitr::include_graphics(file.path(img_path, "whitlock_17.1-2.png"))
```

+ Slope is 10.64
+ Intercept is 0.88
+ Line is $y = 10.64x + 0.88$. **That's our FITTED MODEL!!**
  + $Y = 10.64X_1 + 0.88 + \epsilon$

+ This model formula says that lions who on average have 50% black noses are on average 6.2 years old.
  + 10.64(0.5) + 0.88 = 6.2
---

# Is that a "good" model?

+ How much variation in the response (`age`) does the predictor (`proportion black`) actually explain? This is $R^2$.
+ Do we have statistical confidence in that line-of-best fit?
+ How accurate are our predictions likely to be?

---

# Null-hypothesis testing and P-values

+ **P-values** are one of the most notoriously misunderstood concepts. They tell you: 
  + **_Assuming the null hypothesis is true, what is the probability of observing my data?_**
  
  
+ They DO NOT tell you:
  + What is the probability that this result I observe is real?
  + Is the null hypothesis wrong?
  + Is the null hypothesis right?
  + Is the alternative hypothesis wrong?
  + Is the alternative hypothesis right?
  + They really don't tell you much at all, in fact

---

# Null hypotheses are _set in stone_

+ Each statistical test you do relies on a highly specific null hypothesis that is _always associated with that statistical test._ There is 0 creativity or wiggle-room. 
<br><br>
+ In linear models, the null hypotheses are:
  + All $\beta_n = 0$ (coefficients = 0)
  + The $R^2 = 0$
<br><br>
+ Each estimated parameter has an associated P-value

---

# Statistical significance is mental gymnastics

> Remember: P-values give the probability of observing your data/results _when assuming a TRUE null hypothesis._

If a P-value is very very small, we say: Gee! That's a small probability! I don't think it's likely that things with low probalities happen, so maybe actually something else besides the null is going on. _We call this significant._

If a P-value is not very small, we say: Gee! I think that probabilities that are not very small could totally come to pass. It's not unreasonable to maybe observe this data under the null. _We call this not significant._


---

# A common threshold for "small" is P < 0.05

This number is not special. It is not magic. It's an "historical accident." [See here](https://www.bmj.com/rapid-response/2011/11/03/origin-5-p-value-threshold)


> "...If one in twenty does not seem high enough odds, we may, if we prefer it, draw the line at one in fifty or one in a hundred. Personally, the writer prefers to set a low standard of significance at the 5 per cent point, and ignore entirely all results which fails to reach this level. A scientific fact should be regarded as experimentally established only if aproperly designed experiment rarely fails to give this level of
significance..." --RA Fisher

---

# Back to our "smallest deviations" lions

```{r out.width = '800px', echo=F}
knitr::include_graphics(file.path(img_path, "whitlock_17.1-2.png"))
```


Parameter | Estimate | P-value
--------------------|--------------|--------
Slope (a coefficient) | 10.64 | 7.68e-08 
Intercept (a coefficient) | 0.88 | 0.133
$R^2$ | 0.6113 | 7.68e-08 

---

# Interpreting $R^2$

.small[
+ The proportion black variable explains **61.13%** of the variation in lion age _in this dataset_
+ For one of these lions, if I know the proportion black, I know about 61% of what there is to know about how old that lion is
+ If all residuals are 0, then $R^2 = 1$. Aka, if all points precisely are along the regression line, I know entirely what there is to know (100%) about lion age, *in the given dataset*
<br>
--
<br>
+ There are additional methods one can use to determine how good a given PREDICTION is.
+ That model was built from a given dataset, so we only know how well that line-of-best-fit (model!) works for the data at hand (61%). We'd have to test how well this line-of-best-fit works on _other data_ to know how good its _predictions_ are.
]

---

# Reminder:

.pull-left[
### Hypothesis-testing ("science")
.small[
+ Predictors are based on experimental setup
+ *Specific* goal of knowing how those *specific* predictors affect response
]]

.pull-right[
### Exploratory ("industry"/"big-data")
.small[
+ You have _a bunch_ of data and need to figure out, which predictors should I use in my model to best explain the response?
+ Less likely you care about specific effects of individual predictors
+ *In _this class_, we are going to learn GLMs from this _perspective._*
]]

---

# Linear models ("regression and friends")

+ Explain variation in a *numeric response* variable using *any type and combination of* predictors

+ Key assumptions:
  + Any numeric predictors are linearly related to the response
  + The values of the response variable have equal variance across categories of any categorical predictor
  + The *residuals* of the model are normally distributed. There is NO REQUIREMENT for the data itself to follow a normal distribution
  + Predictors should be independent of one another

_In this class, we will assume assumptions are met when performing analyses._

---

# Numeric predictors must be linearly related

```{r, echo=F, warning = F, message=F, fig.width = 12, fig.height=5}
tibble(y = 10:60) %>%
  mutate(x1 = y * runif(51, 1.25, 2), x2 = y**3) -> dat
ggplot(dat, aes(x = x1, y=y))  +geom_point() + geom_smooth(method = "lm", se =F, size=0.5) + ggtitle("Linear relationship") + xlab("X") + ylab("Y")-> p1
ggplot(dat, aes(x = x2, y=y))  +geom_point() + geom_smooth(method = "lm", se =F, size=0.5) + ggtitle("NOT a linear relationship")+ xlab("X") + ylab("Y")-> p2
p1 + p2
```

---

# Categorical predictors must show equal variance of *response*

```{r, echo=F, warning = F, message=F, fig.width = 12, fig.height=5}
tibble("categorical predictor" = c(rep("category 1", 50), rep("category 2", 50), rep("category 3", 50)),
       "response values" = c(rnorm(50, 10, 2), rnorm(50, 20, 2), rnorm(50, 5, 2))) %>%
  ggplot(aes(x = `categorical predictor`, y = `response values`, color = `categorical predictor`)) +  geom_jitter(size=2, width = 0.1) + theme(legend.position = "none", plot.title = element_text(size = rel(2.0))) + ggtitle("Equal variance across groups :)") -> p1


tibble("categorical predictor" = c(rep("category 1", 50), rep("category 2", 50), rep("category 3", 50)),
       "response values" = c(rnorm(50, 10, 2), rnorm(50, 20, 7), rnorm(50, 5, 0.2))) %>%
  ggplot(aes(x = `categorical predictor`, y = `response values`, color = `categorical predictor`)) +  geom_jitter(size=2, width = 0.1) + theme(legend.position = "none", plot.title = element_text(size = rel(2.0))) + ggtitle("UNEQUAL variance across groups :(") -> p2

p1 + p2
```
---

# Model _residuals_ are normally distributed

```{r out.width = '900px', echo=F}
knitr::include_graphics(file.path(img_path, "whitlock_17.1-2.png"))
```

---

# Let's build a model


```{r, message=F, warning=F}
library(palmerpenguins) # to access penguins dataset

penguins 

```

---

# Make it fit better on slides

```{r}
penguins %>%
  rename(bill_len = bill_length_mm,
         bill_dep = bill_depth_mm,
         flipper = flipper_length_mm,
         mass    = body_mass_g) -> peng

peng
```

---
  

# Linear regression

+ To what extent does flipper length explain variation in bill length?

+ How strong (if any?) is the relationship between these variables?

+ Response variable: `bill_len`
+ Predictor variable: `flipper`

---

# We build linear models with the function `lm()`

### `lm(response ~ predictor(s), data = name_of_dataframe)`

---

```{r}
# Model with bill_len response and flipper predictor
fitted_model <- lm(bill_len ~ flipper, data = peng)

# Examine model output ("ugly version")
summary(fitted_model)
```

---

# Use the `broom` and `modelr` packages to examine output

```{r}
broom::tidy(fitted_model)

broom::glance(fitted_model)

modelr::rsquare(fitted_model, peng)
```

---

# How about species as a predictor?

+ To what extent does species explain variation in bill length?
+ Do different species have different mean bill lengths?

--

```{r}
fitted_model_species <- lm(bill_len ~ species, data = peng)

# Let's first look at R^2
broom::glance(fitted_model_species) %>%
  select(r.squared, p.value)
```

---

# The model coefficients are directly related to the means


```{r}
broom::tidy(fitted_model_species)
```


```{r}
peng %>% 
  group_by(species) %>%
  summarize(mean_bill_len = mean(bill_len, na.rm=T))
```
---

# Do you miss the ANOVA table? 

> Shoutout to how much you loved or will love this topic in Biometry!

```{r}
as_anova <- aov(fitted_model_species)
summary(as_anova)
```

---


# How about both?

#### This model *controls for variation across species.* It asks:

+ Controlling for species, to what extent does flipper length explain variation in bill length? 
+ Is there a relationship between flipper length and bill length, when controlling for species?
<br><br>
+ Controlling for flipper length, to what extent does the species explain variation in bill length? 
+ Do different species have significantly different bill lengths, when controlling for flipper length?

<br>
```{r}
fitted_model_both <- lm(bill_len ~ flipper + species, data = peng)
```

---

# This model explains ~77.6% of variation in bill length

+ In this dataset, if we know the flipper length and species, we know ~77.6% of what there is to know about bill length
+ With multiple predictors, it's challenging to interpret coefficients. We're going to focus on $R^2$ in these circumstances.

```{r}
# Just look at R^2
broom::glance(fitted_model_both) %>%
  select(r.squared, p.value)
```

---

# Interaction effects

+ Is the bill_len/flipper relationship the same or different across species? **Look at slopes.**

```{r}
ggplot(peng) + 
  aes(x = flipper, y = bill_dep, color = species) + 
  geom_point() + 
  geom_smooth(method = "lm")
```


---

# Testing for interaction effects 

```{r}
fitted_model_both_int <- lm(bill_len ~ flipper * species, data = peng)
broom::tidy(fitted_model_both_int)
```

---

# Why it's so important to control for *confounding factors*

.pull-left[
```{r, fig.width = 4}
ggplot(peng) + 
  aes(x = bill_len, y = bill_dep) +  #<<
  geom_point() + 
  geom_smooth(method = "lm")
```
]
.pull-right[
```{r, fig.width = 4}
ggplot(peng) + 
  aes(x = bill_len, y = bill_dep,
      color = species) +  #<<
  geom_point() + 
  geom_smooth(method = "lm")
```
]
---

# Into the Machine Learning World

+ Use _statistics_ to determine optimal predictors for the **bias/variance trade-off**
```{r out.width = '400px', echo=F}
knitr::include_graphics(file.path(img_path, "whitlock_17.1-2.png"))
```

+ Fit model
+ Run diagnostics to ask how badly assumptions were violated
+ Run diagnostics to ask how well the model performs

---

```{r}
peng_nona <- peng %>% drop_na() # step() gets irritated with NAs

# predictor as period .  means: use all!!
full_model <- lm(bill_len ~ ., data = peng_nona)

# Use step() function to pick which predictors are worth keeping
final_model <- step(full_model, trace=FALSE)
```

---
```{r}
broom::tidy(full_model) %>%
  pull(term)

broom::tidy(final_model) %>%
  pull(term)


broom::glance(final_model) %>%
  select(r.squared, p.value)
```
